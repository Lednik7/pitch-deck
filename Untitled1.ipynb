{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf5595-cd37-48ce-a5f0-a824fde00cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "from diffusers import KandinskyV22PriorPipeline, KandinskyV22ControlnetPipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "class KandyControlnet:\n",
    "    def __init__(self, seed=42):\n",
    "        self.pipe_prior = KandinskyV22PriorPipeline.from_pretrained(\n",
    "            \"kandinsky-community/kandinsky-2-2-prior\", torch_dtype=torch.float16\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # self.controlnet_pipe = KandinskyV22ControlnetPipeline.from_pretrained(\n",
    "        #     \"kandinsky-community/kandinsky-2-2-controlnet-depth\", torch_dtype=torch.float16\n",
    "        # ).to(\"cuda\")\n",
    "\n",
    "        self.pipe = DiffusionPipeline.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "        self.generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "    \n",
    "    def make_hint(self, image):\n",
    "        image = np.array(image)\n",
    "        detected_map = torch.from_numpy(image).float() / 255.0\n",
    "        hint = detected_map.permute(2, 0, 1)\n",
    "        return hint\n",
    "\n",
    "    def color_mask(self, array, r_lim, g_lim, b_lim):\n",
    "        \"\"\"\n",
    "        array : m x n x 3 array of colors\n",
    "        *_lim are 2-element tuples, where the first element is expected to be <= the second.\n",
    "        \"\"\"\n",
    "        r_mask = ((array[..., 0] >= r_lim[0]) & (array[..., 0] <= r_lim[1]))\n",
    "        g_mask = ((array[..., 1] >= g_lim[0]) & (array[..., 1] <= g_lim[1]))\n",
    "        b_mask = ((array[..., 2] >= b_lim[0]) & (array[..., 2] <= b_lim[1]))\n",
    "        return r_mask & g_mask & b_mask\n",
    "\n",
    "    def generate_mask(self, path2image, r=(220, 255), g=(220, 255), b=(220, 255), height=768, width=1024):\n",
    "        img = Image.open(path2image).resize((width, height))\n",
    "        mask = self.color_mask(np.array(img), r, g, b)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        mask = np.concatenate([mask, mask, mask], axis=-1) \n",
    "        return mask\n",
    "    \n",
    "    def generate_image(self, prompt, negative_prompt, mask:np.array=None, height=768, width=1024):\n",
    "        # assert mask.shape[:2] == (height, width)\n",
    "        # print(mask.shape)\n",
    "        # We pass the prompt and negative prompt through the prior to generate image embeddings\n",
    "        prompt = prompt\n",
    "        negative_prior_prompt = negative_prompt\n",
    "\n",
    "\n",
    "        image_emb, zero_image_emb = self.pipe_prior(\n",
    "            prompt=prompt, negative_prompt=negative_prior_prompt, generator=self.generator,\n",
    "        ).to_tuple()\n",
    "\n",
    "        # Now we can pass the image embeddings and the depth image we extracted to the controlnet pipeline. With Kandinsky 2.2, only prior pipelines accept `prompt` input. You do not need to pass the prompt to the controlnet pipeline.\n",
    "        kwargs = dict(\n",
    "            image_embeds=image_emb,\n",
    "            negative_image_embeds=zero_image_emb,\n",
    "            num_inference_steps=50,\n",
    "            generator=self.generator,\n",
    "            num_images_per_prompt=1,\n",
    "            height=768,\n",
    "            width=1024,\n",
    "        )\n",
    "        \n",
    "        if mask is not None: \n",
    "            hint = self.make_hint(mask.astype(np.float32)).unsqueeze(0).half().to(\"cuda\")\n",
    "            kwargs.update(dict(hint=hint))\n",
    "            image = self.controlnet_pipe(**kwargs).images[0]\n",
    "        else:\n",
    "            image = self.pipe(**kwargs).images[0]\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def generate_background(self, path2image, prompt, negative_prompt=\"complex image, complex\", image_size=(1600, 900)):\n",
    "        mask = self.generate_mask(path2image)\n",
    "        # image = self.generate_image(prompt, negative_prompt, mask=mask)\n",
    "        image = self.generate_image(prompt, negative_prompt)\n",
    "        return image.resize((image_size))\n",
    "                          \n",
    "    def generate_foreground(self, path2image, prompt, negative_prompt=\"complex image, complex\", image_size=(1600, 900)):\n",
    "        mask = self.generate_mask(path2image)\n",
    "        mask = np.logical_not(mask)\n",
    "        # image = self.generate_image(prompt, negative_prompt, mask=mask)\n",
    "        image = self.generate_image(prompt, negative_prompt)\n",
    "        return image.resize((image_size))\n",
    "    \n",
    "    def combine(self, path2image, prompt, negative_prompt=\"complex image, complex\", image_size=(1600, 900)):\n",
    "        \n",
    "        combinations = []\n",
    "        \n",
    "        image = np.array(Image.open(path2image).resize(image_size)).astype(np.uint8)\n",
    "        mask = Image.fromarray(self.generate_mask(path2image).astype(np.uint8)).resize(image_size)\n",
    "        gen_1 = self.generate_background(path2image, prompt, negative_prompt, image_size)\n",
    "        gen_2 = self.generate_foreground(path2image, prompt, negative_prompt, image_size)\n",
    "        \n",
    "        gen_1, gen_2, mask = [np.array(x) for x in [gen_1, gen_2, mask]]\n",
    "        \n",
    "        background_mask = mask \n",
    "        foreground_mask = np.logical_not(mask)\n",
    "        \n",
    "        foreground_image = image * foreground_mask \n",
    "        background_image = image * background_mask\n",
    "        \n",
    "        gen_1_with_foreground = gen_1 * background_mask + image * foreground_mask \n",
    "        gen_2_with_foreground = gen_2 * background_mask + image * foreground_mask \n",
    "        \n",
    "        combinations.append(image)\n",
    "        combinations.append(mask * 255)\n",
    "        combinations.append(gen_1)\n",
    "        combinations.append(gen_2)\n",
    "        combinations.append(gen_1_with_foreground)\n",
    "        combinations.append(gen_2_with_foreground)\n",
    "        combinations = [Image.fromarray(x) for x in combinations]\n",
    "        return combinations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52a875-41ec-4967-b103-82a7743e43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kandy_controlnet = KandyControlnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff7d84d-5618-498f-a80c-5fd880200db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(src_dir, filename)\n\u001b[1;32m      9\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_dir, filename)\n\u001b[0;32m---> 10\u001b[0m combinations \u001b[38;5;241m=\u001b[39m \u001b[43mkandy_controlnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39mvstack(combinations))\u001b[38;5;241m.\u001b[39msave(dst_path)\n",
      "Cell \u001b[0;32mIn[1], line 95\u001b[0m, in \u001b[0;36mKandyControlnet.combine\u001b[0;34m(self, path2image, prompt, negative_prompt, image_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(path2image)\u001b[38;5;241m.\u001b[39mresize(image_size))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     94\u001b[0m mask \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_mask(path2image)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\u001b[38;5;241m.\u001b[39mresize(image_size)\n\u001b[0;32m---> 95\u001b[0m gen_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_background(\u001b[43mpath\u001b[49m, prompt, negative_prompt, image_size)\n\u001b[1;32m     96\u001b[0m gen_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_foreground(path, prompt, negative_prompt, image_size)\n\u001b[1;32m     98\u001b[0m gen_1, gen_2, mask \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [gen_1, gen_2, mask]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "src_dir = \"pattern_1\"\n",
    "dst_dir = \"generated_1\"\n",
    "prompt = \"crypto on sides\"\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if '.ipynb_checkpoints' not in filename:\n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "        combinations = kandy_controlnet.combine(src_path, prompt)\n",
    "        Image.fromarray(np.vstack(combinations)).save(dst_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
